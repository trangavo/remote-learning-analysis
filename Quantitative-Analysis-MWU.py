# -*- coding: utf-8 -*-
"""Quantitative-V2-organized.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JxbvCuhr5DJwOor05XzCqSdAPbkCHzA_

# Install and Import Packages
"""

!pip install plotly>=4.7.1
!wget https://github.com/plotly/orca/releases/download/v1.2.1/orca-1.2.1-x86_64.AppImage -O /usr/local/bin/orca
!chmod +x /usr/local/bin/orca

!sudo apt-get update
!apt-get install xvfb libgtk2.0-0 libgconf-2-4

# Import the packages we'll be using
import rpy2 as r
import pandas as pd
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt
import scipy.stats as sts
import matplotlib
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from google.colab import files

"""# Data Pre-processing

## Import and process data
"""

from google.colab import drive 
drive.mount('/content/gdrive')

# Define more concise headers for the data
headers = ["timestamp","level","country","is_online",
           "first_survey","agree","primary_mode","preferred_mode",
           "why_mode","platforms_used","methods_used",
           "techniques_outside","remote_enjoy","remote_motivated",
           "remote_satisfied","remote_engaging","remote_distracted",
           "remote_questions","remote_changes","prior_enjoy",
           "prior_motivated","prior_satisfied","prior_engaging",
           "prior_distracted","prior_questions","prior_changes",
           "preference","why_preference"]

# Read in the raw data
full_data = pd.read_csv("/content/gdrive/My Drive/Summer 2020/Minerva Internship/Team Stein/raw_data.csv", skiprows=[0], names=headers, na_values="?")

full_data.shape

# Define some other lists that will be useful

# List of just the Likert questions about remote instructions
remote_survey_q = ["remote_enjoy","remote_motivated",
                   "remote_satisfied","remote_engaging",
                   "remote_distracted","remote_questions"]
change_survey_q = ["change_enjoy","change_motivated",
                   "change_satisfied","change_engaging",
                   "change_distracted","change_questions"]
remote_q_long = ["I enjoy having courses online",
                 "I feel motivated to learn",
                 "I am satisfied with the instruction\nof my online courses",
                 "My courses are engaging",
                 "I am often distracted when doing\ncourse work / attending classes",
                 "I often ask questions, comment, join discussions"]
change_q_long = ["I enjoy",
                 "I feel motivated to learn",
                 "I am satisfied with the instruction",
                 "My courses are engaging",
                 "I am often distracted when doing\ncourse work / attending classes",
                 "I often ask questions, comment, join discussions"]

# Drop the rows that we're not going to be using
data = full_data.drop(["timestamp","agree"], axis=1)

# Drop duplicates
duplicate = data[data.duplicated()]
print('# of duplicates: ', len(duplicate))
print('Valid entries: ', duplicate[duplicate['primary_mode'].isna()==False].index)
print('# of duplicates for valid entries: ', len(duplicate[duplicate['primary_mode'].isna()==False].index))
print('NaN entries: ', duplicate[duplicate['primary_mode'].isna()].index)
print('# of duplicates for NaN entries: ', len(duplicate[duplicate['primary_mode'].isna()]))

data = data.drop(duplicate.index, axis=0)
data = data.reset_index(drop=True)

data.head()

# Recode Likert responses into numerical code
likert_dict = {"Strongly Disagree": 1, "Disagree": 2, "Neutral": 3, 
               "Agree": 4, "Strongly Agree": 5}
likert_code = {"remote_enjoy":       likert_dict,
               "remote_motivated":   likert_dict,
               "remote_satisfied":   likert_dict,
               "remote_engaging":    likert_dict,
               "remote_distracted":  likert_dict,
               "remote_questions":   likert_dict,
               "prior_enjoy":       likert_dict,
               "prior_motivated":   likert_dict,
               "prior_satisfied":   likert_dict,
               "prior_engaging":    likert_dict,
               "prior_distracted":  likert_dict,
               "prior_questions":   likert_dict}
data.replace(likert_code, inplace=True)

# Recode Primary mode entries into shorter things
modes = {"primary_mode":   {"Live classes (ie: Zoom, Google Meet etc.)": "live",
                            "Uploaded or emailed Materials": "upload",
                            "Recorded Lectures": "recorded",
                            "Discussion forums/chats": "chat"},
         "preferred_mode":   {"Live classes (ie: Zoom, google meet etc.)": "live",
                            "Uploaded or emailed Materials": "upload",
                            "Recorded Lectures/Videos": "recorded",
                            "Discussion forums/chats": "chat"}}
data.replace(modes, inplace=True)

data["change_enjoy"] = data["remote_enjoy"] - data["prior_enjoy"]
data["change_motivated"] = data["remote_motivated"] - data["prior_motivated"]
data["change_satisfied"] = data["remote_satisfied"] - data["prior_satisfied"]
data["change_engaging"] = data["remote_engaging"] - data["prior_engaging"]
data["change_distracted"] = data["remote_distracted"] - data["prior_distracted"]
data["change_questions"] = data["remote_questions"] - data["prior_questions"]

data["active"] = data["methods_used"].str.contains(pat='In-class assessments/quizzes|Small group activities|Whole class discussion/debate|Q&A with students\' questions|Classroom chat')
data["passive"] = data["methods_used"].str.contains(pat='Lecture/presentation|Explanation using Diagrams/White Boards/other media')

data["fully_active"] = data["methods_used"].str.contains(pat='Small group activities|Whole class discussion/debate')
data["partly_active"] = data["methods_used"].str.contains(pat='In-class assessments/quizzes|Q&A with students\' questions|Classroom chat')

data["outside_passive"] = data["techniques_outside"].str.contains(pat='Video lectures|Video content|Posted readings/study material')
data["outside_interactive"] = data["techniques_outside"].str.contains(pat='Discussion/Chat Forums|Live office hours|Email Q&A with instructors')
data["outside_assignments"] = data["techniques_outside"].str.contains(pat='Assignments/un-proctored exams')

data.head()

data.to_csv('processed_data_1.csv')

"""## Split to different datasets"""

# Create sub-lists for different eductional levels / settings
# We'll only be using undergrad datasets from now
ug = data[data.level.eq("Undergraduate (studying for associates or bachelors degrees)")]
ug = ug.reset_index()
hs = data[data.level.eq("High school/A-levels/Gymnasium")]
hs = hs.reset_index()

# Drop NA rows for Likert score
ug = ug.dropna(axis=0, subset=['primary_mode'])

ug.isna().sum()

ug['is_online_short'] = ug['is_online']
ug['is_online_short'][(ug['is_online_short'] != 'Yes') & (ug['is_online_short'] != 'No')] = 'Other'

def number_ops(data):
    if pd.isna(data):
        return -1
    elif 'My instructors do not use live instruction.' in data:
        return 0
    else:
        return data.count(',') + 1

ug['num_methods'] = pd.Series(ug['methods_used'].apply(number_ops)).rename('num_methods')
ug['num_techniques'] = pd.Series(ug['techniques_outside'].apply(number_ops)).rename('num_techniques')

ug.to_csv('ug_processed.csv')

ug.shape

ug.head()

ug.tail()

# Create frames for undergraduates learning synchronously and asynchronously
ug_sync = ug[ug.primary_mode.eq("live")]
ug_async = ug[ug["primary_mode"] != "live"]

# Create frames for active / passive / mixed methods
ug_active_only = ug[ug.active & (ug.passive==False)]
ug_passive_only = ug[(ug.active==False) & ug.passive]
ug_act_pass_mix = ug[ug.active & ug.passive]

ug_fully_active = ug[ug.fully_active.eq(True)]
ug_partly_active = ug[ug.partly_active.eq(True)]
ug_passive = ug[ug.passive.eq(True)]

# Create analogous frames for high-school students
hs_sync = hs[hs.primary_mode.eq("live")]
hs_async = hs[hs["primary_mode"] != "live"]

# Create frames for active / passive / mixed methods
hs_active_only = hs[hs.active & (hs.passive==False)]
hs_passive_only = hs[(hs.active==False) & hs.passive]
hs_act_pass_mix = hs[hs.active & hs.passive]

# Create frames for preference undergrad
ug_prefer_inperson = ug[ug['preference']=='In-person Courses']
ug_prefer_remote = ug[ug['preference']=='Online Courses']
ug_prefer_no = ug[ug['preference'].isna()]

# Create frames for preference high school
hs_prefer_inperson = hs[hs['preference']=='In-person Courses']
hs_prefer_remote = hs[hs['preference']=='Online Courses']
hs_prefer_no = hs[hs['preference'].isna()]

# Name the datasets
subset_ls = [ug_sync, ug_async, ug_active_only, ug_passive_only, ug_act_pass_mix, ug_fully_active, ug_partly_active, ug_passive, \
             hs_sync, hs_async, hs_active_only, hs_passive_only, hs_act_pass_mix, ug_prefer_inperson, ug_prefer_remote, ug_prefer_no,\
            hs_prefer_inperson, hs_prefer_remote, hs_prefer_no]
subset_name = ['Synchronous', 'Asynchronous', 'Active only', 'Passive only', 'Mixed', 'Fully active', 'Partly active', 'Passive', \
               'Synchronous', 'Asynchronous', 'Active only', 'Passive only', 'Mixed', 'Prefer in-person', 'Prefer remote', 'Prefer none',\
              'Prefer in-person', 'Prefer remote', 'Prefer none']
for i in range(len(subset_ls)):
    subset_ls[i].name = subset_name[i]

ug['techniques_outside'].str.contains('Email',case=False).value_counts()

"""# Comparison Functions"""

# Set up our Cohen's d function
def cohens_d (x,y):
    n1 = x.shape[0]
    n2 = y.shape[0]
    sd = (((n1 - 1) * x.var() + (n2 - 1) * y.var())/(n1 + n2 - 2))**0.5
    return ((x.mean()-y.mean())/sd)

def eff(U, n_a, n_b):
    # print(U, n_a, n_b)
    return U / (n_a * n_b)

# Compare the mean of 3 datasets

def mean_comparison(a, b, c):
    dim = (6,5)
    aa = np.zeros(dim)
    bb = np.zeros(dim)
    cc = np.zeros(dim)


    for i in range (6):
        for j in range (5):
            cc[i,j] = c[remote_survey_q[i]].value_counts(normalize=True)[j+1]
            aa[i,j] = a[remote_survey_q[i]].value_counts(normalize=True)[j+1] 
            bb[i,j] = b[remote_survey_q[i]].value_counts(normalize=True)[j+1]

    for q in range (6):
        ind = np.arange(5) 
        width = 0.2       
        
        plt.bar(ind + width + width, aa[q], width, label=a.name)
        plt.bar(ind, cc[q], width, label=c.name)
        plt.bar(ind + width, bb[q], width, label=b.name)
        

        plt.ylabel('Fraction of Responses')
        plt.title(remote_q_long[q])

        plt.xticks(ind + width , ('Strongly\nDisagree', 'Disagree',
                                     'Neutral', 'Agree', 'Strongly\nAgree'))
        plt.legend(loc='best')
        plt.show()
        #print (stats.mannwhitneyu(ug_passive_only[remote_survey_q[q]],ug_act_pass_mix[remote_survey_q[q]]))
        print (a.name,"{:.3}".format(a[remote_survey_q[q]].mean()))
        print (c.name,"{:.3}".format(c[remote_survey_q[q]].mean()))
        print (b.name,"{:.3}".format(b[remote_survey_q[q]].mean()))
        #print ("Cohen's d =","{:.2}".format(cohens_d(ug_passive_only[remote_survey_q[q]],ug_act_pass_mix[remote_survey_q[q]])))

def mean_comparison_plotly(groupa, groupb):

  x = ['Enjoyment', 'Motivation', 'Satisfaction', 'Engagement', 'Distraction', 'Participation']

  fig = go.Figure()

  a = [[], []]
  b = [[], []]

  name1 = groupa.name
  name2 = groupb.name

  for col in remote_survey_q:
    a[0].append(groupa[col].mean())
    b[0].append(groupb[col].mean())
    a[1].append(groupa[col].std())
    b[1].append(groupb[col].std())

  fig.add_trace(go.Bar(
      x=x,
      y=a[0],
      name=name1,
      marker_color='#26828e',
      error_y=dict(type='data', array=a[1])
  ))
  fig.add_trace(go.Bar(
      x=x,
      y=b[0],
      name=name2,
      marker_color='#b5de2b',
      error_y=dict(type='data', array=b[1])
  ))

  fig.update_layout(
        autosize=False,
        width=1000,
        height=700,
        title=f'Comparison of mean of remote learning experiences between {name1} and {name2}',
        title_x =0.5,
        title_y = 0.95,
        font=dict(
            family="sans-serif",
            size=16,
        ),
        xaxis=dict(
            title='Remote learning experiences',
            titlefont_size=16,
            tickfont_size=14,
        ),
        yaxis=dict(
            title='Likert scores mean',
            titlefont_size=16,
            tickfont_size=14,
        ),
        legend=dict(
            x=0.9,
            y=1.05,
            font=dict(
                family="sans-serif",
                size=14,
            ),
            bgcolor='rgba(255, 255, 255, 0)',
            bordercolor='rgba(255, 255, 255, 0)',

            # traceorder='reversed'
        ),
          
        barmode='group',
        bargap=0.15, # gap between bars of adjacent location coordinates.
        bargroupgap=0.1, # gap between bars of the same location coordinate.
        paper_bgcolor = 'rgba(0,0,0,0)',
        plot_bgcolor = 'rgba(0,0,0,0)'
    )

  fig.show()

mean_comparison_plotly(ug_sync, ug_async)

ug_sync['remote_enjoy'].mean()

ug_sync['remote_enjoy'].std()

# Comparing the Likert score between 2 groups and return the summary table

# table_size = pd.DataFrame(columns=['name', 'size'])
def mwu_comparison(a, b):
    # table_size.head()
    # table_size = table_size.append({'name': a.name,'size': a.shape[0]}, ignore_index=True)
    # table_size = table_size.append({'name': b.name,'size': b.shape[0]}, ignore_index=True)
    # print(table_size)
    acount = np.zeros((6,5))
    bcount = np.zeros((6,5))
    for i in range (6):
        for j in range (5):
            if j+1 in a[remote_survey_q[i]].value_counts(normalize=True).index:
                acount[i,j] = a[remote_survey_q[i]].value_counts(normalize=True)[j+1]
            if j+1 in b[remote_survey_q[i]].value_counts(normalize=True).index:
                bcount[i,j] = b[remote_survey_q[i]].value_counts(normalize=True)[j+1]
    table_result = pd.DataFrame(columns=['question', f'{a.name} median (n = {a.shape[0]})', f'{b.name} median (n = {b.shape[0]})', 'cohens d', 'f', 'p-value'])

    

    for q in range (6):
        ind = np.arange(5) 
        width = 0.35  
        plt.bar(ind, acount[q], width, label=a.name)
        plt.bar(ind + width, bcount[q], width, label=b.name)
        
        plt.ylabel('Fraction of Responses')
        plt.title(remote_q_long[q])

        plt.xticks(ind + width / 2, ('Strongly\nDisagree', 'Disagree',
                                     'Neutral', 'Agree', 'Strongly\nAgree'))
        plt.legend(loc='best')
        plt.show()

        amed = "{:.3}".format(a[remote_survey_q[q]].median())
        bmed = "{:.3}".format(b[remote_survey_q[q]].median())
        d = "{:.3}".format(cohens_d(a[remote_survey_q[q]],b[remote_survey_q[q]]))
        mwu = stats.mannwhitneyu(a[remote_survey_q[q]],b[remote_survey_q[q]], alternative='two-sided')
        U_a = mwu[0]
        p = "{:.3}".format(mwu[1])
        f = "{:.3}".format(eff(U_a, a.shape[0], b.shape[0]))
        # eta2 = "{:.3}".format(mwu[1] / (a.shape[0] + b.shape[0] - 1))

        print(f'{a.name} shape: {a.shape}, {b.name} shape: {b.shape}')
        print('MWU results: ', mwu)
        
        print(f'{a.name} median: {amed}')
        print(f'{b.name} median: {bmed}')
        print(f'cohens d: {d}')
        print(f'f: {f}')
        # print(f'eta2: {eta2}')
        table_result = table_result.append({'question': remote_survey_q[q], f'{a.name} median (n = {a.shape[0]})': amed, f'{b.name} median (n = {b.shape[0]})': bmed, 'cohens d': d, 'f': f, 'p-value': p}, ignore_index=True)
    # table_result.to_excel(writer,'Sheet1', startrow = writer.sheets['Sheet1'].max_row + 1)
    # writer.save()

    mean_comparison_plotly(a, b)
    return table_result

# writer = pd.ExcelWriter('output.xlsx')
# pd.DataFrame(columns=['result table']).to_excel(writer, 'Sheet1')

"""# Pairwise Comparisons

## Synchronous vs. Asynchronous
"""

mwu_comparison(ug_sync, ug_async)

"""## Active vs. Passive"""

mwu_comparison(ug_active_only, ug_passive_only)

mwu_comparison(ug_act_pass_mix, ug_active_only)

mwu_comparison(ug_act_pass_mix, ug_passive_only)

mean_comparison(ug_active_only, ug_passive_only, ug_act_pass_mix)

mean_comparison(ug_fully_active, ug_passive, ug_partly_active)

"""## Prefer in-person vs. Prefer remote"""

mwu_comparison(ug_prefer_remote, ug_prefer_inperson)

"""## Effects of number of methods/platforms/techniques used

### Exceptions
"""

# equals "No live instructions" 
print(ug[ug['methods_used'] == 'My instructors do not use live instruction.'].index)

# "No live instructions" but still choose other boxes
print(ug['methods_used'][(ug['methods_used'].isna() == False) & (ug['methods_used'] != 'My instructors do not use live instruction.')\
   & (ug['methods_used'].str.contains('My instructors do not use live instruction.'))].index)

# contains "No live instructions"
print(ug['methods_used'][(ug['methods_used'].isna() == False) \
   & (ug['methods_used'].str.contains('My instructors do not use live instruction.'))].index)

# Unique number of methods
print(ug['num_methods'].value_counts(normalize=True))
ug_by_methods = ug.groupby('num_methods')

"""### Pairwise comparison"""

def num_comp(data, num, q, k):
    methods_less = data[(data[num] >= q) & (data[num] < k)]
    methods_more = data[data[num] >= k]
    subset_ls.extend([methods_less, methods_more])
    subset_name.extend([f'{num}: >={str(q)}, <{str(k)}', f'{num}: >={str(k)}'])
    methods_less.name = f'>={str(q)}, <{str(k)}'
    methods_more.name = f'>={str(k)}'
    # print(f'>={str(q)}, <{str(k)}', methods_less.shape)
    # print(f'>={str(k)}', methods_more.shape)
    return mwu_comparison(methods_more, methods_less)

"""#### Undergrad"""

num_comp(ug, 'num_methods', 0, 1)

num_comp(ug, 'num_methods', 1, 2)

num_comp(ug, 'num_methods', 1, 3)

num_comp(ug, 'num_methods', 1, 4)

num_comp(ug, 'num_methods', 1, 5)

"""## Combinations of types of methods"""

ugcat1 = ug[(ug['passive']==True) & (ug['partly_active']==False) & (ug['fully_active']==False)]
ugcat2 = ug[(ug['passive']==False) & (ug['partly_active']==True) & (ug['fully_active']==False)]
ugcat3 = ug[(ug['passive']==False) & (ug['partly_active']==False) & (ug['fully_active']==True)]
ugcat4 = ug[(ug['passive']==True) & (ug['partly_active']==True) & (ug['fully_active']==False)]
ugcat5 = ug[(ug['passive']==True) & (ug['partly_active']==False) & (ug['fully_active']==True)]
ugcat6 = ug[(ug['passive']==False) & (ug['partly_active']==True) & (ug['fully_active']==True)]
ugcat7 = ug[(ug['passive']==True) & (ug['partly_active']==True) & (ug['fully_active']==True)]
ugcats = [ugcat1, ugcat2, ugcat3, ugcat4, ugcat5, ugcat6, ugcat7]

names = ['P','A','F','PA','PF','AF','PAF']
for i in range(len(ugcats)):
    subset_ls.append(ugcats[i])
    subset_name.append(names[i])
    ugcats[i].name = names[i]

"""#### Undergrad"""

types_undergrad = []
for i in range(len(ugcats)-1):
    for j in range(i+1, len(ugcats)):
        print('----------------------')
        print(ugcats[i].name, ugcats[i].shape)
        print(ugcats[j].name, ugcats[j].shape)
        types_undergrad.append(mwu_comparison(ugcats[j], ugcats[i]))

types_undergrad[0]

types_undergrad[1]

types_undergrad[2]

types_undergrad[3]

types_undergrad[4]

types_undergrad[5]

types_undergrad[6]

types_undergrad[7]

types_undergrad[8]

types_undergrad[9]

types_undergrad[10]

types_undergrad[11]

types_undergrad[12]

types_undergrad[13]

types_undergrad[14]

types_undergrad[15]

types_undergrad[16]

types_undergrad[17]

types_undergrad[18]

types_undergrad[19]

types_undergrad[20]

"""Discussion/Chat Forums
Video lectures
Video content
Posted readings/study material
Assignments/un-proctored exams
Live office hours
Email Q&A with instructors

## Techniques used outside of class
"""

ugcat1_o = ug[(ug['outside_passive']==True) & (ug['outside_interactive']==False) & (ug['outside_assignments']==False)]
ugcat2_o = ug[(ug['outside_passive']==False) & (ug['outside_interactive']==True) & (ug['outside_assignments']==False)]
ugcat3_o = ug[(ug['outside_passive']==False) & (ug['outside_interactive']==False) & (ug['outside_assignments']==True)]
ugcat4_o = ug[(ug['outside_passive']==True) & (ug['outside_interactive']==True) & (ug['outside_assignments']==False)]
ugcat5_o = ug[(ug['outside_passive']==True) & (ug['outside_interactive']==False) & (ug['outside_assignments']==True)]
ugcat6_o = ug[(ug['outside_passive']==False) & (ug['outside_interactive']==True) & (ug['outside_assignments']==True)]
ugcat7_o = ug[(ug['outside_passive']==True) & (ug['outside_interactive']==True) & (ug['outside_assignments']==True)]
ugcats_o = [ugcat1_o, ugcat2_o, ugcat3_o, ugcat4_o, ugcat5_o, ugcat6_o, ugcat7_o]

names_o = ['L','I','A','LI','LA','IA','LIA']
for i in range(len(ugcats_o)):
    subset_ls.append(ugcats_o[i])
    subset_name.append(names_o[i])
    ugcats_o[i].name = names_o[i]

techniques_undergrad = []
for i in range(len(ugcats_o)-1):
    for j in range(i+1, len(ugcats_o)):
        print('----------------------')
        print(ugcats_o[i].name, ugcats_o[i].shape)
        print(ugcats_o[j].name, ugcats_o[j].shape)
        techniques_undergrad.append(mwu_comparison(ugcats_o[j], ugcats_o[i]))

techniques_undergrad[0]

techniques_undergrad[1]

techniques_undergrad[2]

techniques_undergrad[3]

techniques_undergrad[4]

techniques_undergrad[5]

techniques_undergrad[6]

techniques_undergrad[7]

techniques_undergrad[8]

techniques_undergrad[9]

techniques_undergrad[10]

techniques_undergrad[11]

techniques_undergrad[12]

techniques_undergrad[13]

techniques_undergrad[14]

techniques_undergrad[15]

techniques_undergrad[16]

techniques_undergrad[17]

techniques_undergrad[18]

techniques_undergrad[19]

techniques_undergrad[20]

"""## Effects of number of techniques and methods, controlling for types"""

print(ug.shape)
print(ug.columns)
print(ug['num_methods'].value_counts(normalize=True))
print(ug['num_techniques'].value_counts(normalize=True))

def num_diversity_controlled(cat, num):
    print(cat.name)
    if 0 in cat[num].unique():
        cat = cat.drop(cat[cat[num]==0].index, axis=0)
    proportion = cat[num].value_counts(normalize=True)
    print(proportion)
    least = min(cat[num].unique())
#     if sum(proportion.iloc[:(least+2)]) < 0.8:
    return num_comp(cat, num, least, least+1), '---------------', num_comp(cat, num, least, least+2)
#     else:
#         return num_methods_comp(cat, least, least+1)

num_diversity_controlled_undergrad = []
for cat in ugcats:
    num_diversity_controlled_undergrad.append(num_diversity_controlled(cat, 'num_methods'))
    print('-----------------------------------')

num_diversity_controlled_undergrad[0][0]

num_diversity_controlled_undergrad[0][2]

num_diversity_controlled_undergrad[1][0]

num_diversity_controlled_undergrad[1][2]

num_diversity_controlled_undergrad[2][0]

num_diversity_controlled_undergrad[2][2]

num_diversity_controlled_undergrad[3][0]

num_diversity_controlled_undergrad[3][2]

num_diversity_controlled_undergrad[4][0]

num_diversity_controlled_undergrad[4][2]

num_diversity_controlled_undergrad[5][0]

num_diversity_controlled_undergrad[5][2]

num_diversity_controlled_undergrad[6][0]

num_diversity_controlled_undergrad[6][2]

num_tech_diversity_controlled_undergrad = []

for cat in ugcats_o:
    num_tech_diversity_controlled_undergrad.append(num_diversity_controlled(cat, 'num_techniques'))
    print('-----------------------------------')

num_tech_diversity_controlled_undergrad[0][0]

num_tech_diversity_controlled_undergrad[0][2]

num_tech_diversity_controlled_undergrad[1][0]

num_tech_diversity_controlled_undergrad[1][2]

num_tech_diversity_controlled_undergrad[2][0]

num_tech_diversity_controlled_undergrad[2][2]

num_tech_diversity_controlled_undergrad[3][0]

num_tech_diversity_controlled_undergrad[3][2]

num_tech_diversity_controlled_undergrad[4][0]

num_tech_diversity_controlled_undergrad[4][2]

num_tech_diversity_controlled_undergrad[5][0]

num_tech_diversity_controlled_undergrad[5][2]

num_tech_diversity_controlled_undergrad[6][0]

num_tech_diversity_controlled_undergrad[6][2]

"""## Effects of diversity of methods and techniques, controlling for number"""

for cat in ugcats:
    print(cat.name)
    print(cat['num_methods'].value_counts(normalize=True))

# 3 types vs. 1 and 2 types, controlled for number of methods
three_vs_2_and_1_type = []
for num in [3, 4, 5]:
    a = ugcat7[ugcat7['num_methods']==num]
    a.name = f'paf, {num} methods in class'
    subset_ls.append(a)
    subset_name.append(a.name)
    for i in range(len(ugcats)-1):
        b = ugcats[i][ugcats[i]['num_methods']==num]
        b.name = f'{ugcats[i].name}, {num} methods in class'
        subset_ls.append(b)
        subset_name.append(b.name)
        print(a.name, a.shape[0], b.name, b.shape[0])
        three_vs_2_and_1_type.append(mwu_comparison(a, b))

three_vs_2_and_1_type[0]

three_vs_2_and_1_type[1]

three_vs_2_and_1_type[2]

three_vs_2_and_1_type[3]

three_vs_2_and_1_type[4]

three_vs_2_and_1_type[5]

three_vs_2_and_1_type[6]

three_vs_2_and_1_type[7]

three_vs_2_and_1_type[8]

three_vs_2_and_1_type[9]

three_vs_2_and_1_type[10]

three_vs_2_and_1_type[11]

three_vs_2_and_1_type[12]

three_vs_2_and_1_type[13]

three_vs_2_and_1_type[14]

three_vs_2_and_1_type[15]

three_vs_2_and_1_type[16]

three_vs_2_and_1_type[17]

# 2 types vs. 1 type OVERALL, controlled for 2 methods
a = pd.concat([ugcat1, ugcat2, ugcat3])
a = a[a['num_methods']==2]
b = pd.concat([ugcat4, ugcat5, ugcat6])
b = b[b['num_methods']==2]
a.name = '1 type of method, 2 methods'
b.name = '2 type of method, 2 methods'
subset_ls.append(a)
subset_name.append(a.name)
subset_ls.append(b)
subset_name.append(b.name)
print(a.name, a.shape[0], b.name, b.shape[0])

mwu_comparison(b, a)

# 2 types vs. 1 type SPECIFIC, controlled for 2 methods
specific = []
for each in [[ugcat1, ugcat5], [ugcat2, ugcat5], [ugcat1, ugcat6]]:
    a = each[0][each[0]['num_methods']==2]
    b = each[1][each[1]['num_methods']==2]
    a.name = f'{each[0].name}, 2 methods'
    b.name = f'{each[1].name}, 2 methods'
    subset_ls.append(a)
    subset_name.append(a.name)
    subset_ls.append(b)
    subset_name.append(b.name)
    print(a.name, a.shape[0], b.name, b.shape[0])
    specific.append(mwu_comparison(b, a))

specific[0]

specific[1]

specific[2]

# among 1 type, controlled for number of methods
ug1type = [ugcat1, ugcat2, ugcat3]
ug1type_sum = []
for num in [1, 2]:
    for i in range(3):
        for j in range(i+1, 3):
            a = ug1type[i][ug1type[i]['num_methods']==num]
            b = ug1type[j][ug1type[j]['num_methods']==num]
            a.name = f'{ug1type[i].name}, {num} methods'
            b.name = f'{ug1type[j].name}, {num} methods'
            subset_ls.append(a)
            subset_name.append(a.name)
            subset_ls.append(b)
            subset_name.append(b.name)
            print(a.name, a.shape[0], b.name, b.shape[0])
            ug1type_sum.append(mwu_comparison(b, a))

ug1type_sum[0]

ug1type_sum[1]

ug1type_sum[2]

ug1type_sum[3]

ug1type_sum[4]

ug1type_sum[5]

ug2type = [ugcat4, ugcat5, ugcat6]
ug2type_sum = []
for num in [2, 3, 4]:
    for i in range(3):
        for j in range(i+1, 3):
            a = ug2type[i][ug2type[i]['num_methods']==num]
            b = ug2type[j][ug2type[j]['num_methods']==num]
            a.name = f'{ug2type[i].name}, {num} methods'
            b.name = f'{ug2type[j].name}, {num} methods'
            subset_ls.append(a)
            subset_name.append(a.name)
            subset_ls.append(b)
            subset_name.append(b.name)
            print(a.name, a.shape[0], b.name, b.shape[0])
            ug2type_sum.append(mwu_comparison(b, a))

ug2type_sum[0]

ug2type_sum[1]

ug2type_sum[2]

ug2type_sum[3]

ug2type_sum[4]

ug2type_sum[5]

ug2type_sum[6]

ug2type_sum[7]

ug2type_sum[8]

for cat in ugcats:
    print(cat.name)
    print(np.mean(cat['num_methods']))

for cat in ugcats_o:
    print(cat.name)
    print(np.mean(cat['num_techniques']))

"""# Preliminary Analysis

"""

print('Number of countries:', len(ug['country'].unique()))

"""## Plotting functions"""

def pie_plots(ds, col, title, colors, n, legend_x, title_y):
  count = pd.DataFrame(ds[col].value_counts(normalize=True)).reset_index()
  count.columns = [col, 'proportion']
  # count[col][count['proportion'] < 0.001] = 'Other'
  count[col].loc[n:] = 'Other'
  labels = count[col]
  values = count['proportion']
  # fig = go.Figure(data=[go.Pie(labels=labels, values=values, title={'text': title, 'position': 'middle center'}, textinfo='label+percent', marker={'colors': px.colors.sequential.Viridis})])
  # fig.marker(colors=px.colors.sequential.Cividis)
  fig = go.Figure(data=[go.Pie(labels=labels, values=values, textinfo='label+percent', marker={'colors': colors})]
			 )
  fig.update_layout(
    font=dict(
        family="sans-serif",
        size=16,
        # color="black"
    ),
    legend=dict(
        x=legend_x,
        y=0.95,
        traceorder="normal",
        font=dict(
            family="sans-serif",
            size=14,
            # color="black"
        ),
    ), title = title, title_x=0.5, title_y = title_y,
    paper_bgcolor = 'rgba(0,0,0,0)',
		plot_bgcolor = 'rgba(0,0,0,0)'
)
  return fig

def bar_plot(ds1, ds2, col, title, y_title, leg1, leg2):
  count = pd.DataFrame(ds1[col].value_counts(normalize=True)).reset_index()
  count.columns = [col, 'proportion']
  # count[col][count['proportion'] < 0.001] = 'Other'
  # count[col].loc[n:] = 'Other'
  count = count[count[col]>=0]
  # print(count)
  x = count[col]
  y = count['proportion']

  count_ = pd.DataFrame(ds2[col].value_counts(normalize=True)).reset_index()
  count_.columns = [col, 'proportion']
  # count[col][count['proportion'] < 0.001] = 'Other'
  # count[col].loc[n:] = 'Other'
  count_ = count_[count_[col]>=0]
  x_ = count_[col]
  y_ = count_['proportion']

  smed = ds1[col].median()
  amed = ds2[col].median()

  fig = go.Figure(data=[go.Bar(name=leg1, x=x, y=y, marker_color='#26828e', width=[0.4]*5, orientation='v'),\
                        go.Bar(name=leg2, x=x_, y=y_, marker_color='#b5de2b', width=[0.4]*5, orientation='v'),\
                        go.Scatter(y=[0,0.45],x=[smed,smed], line={
              'color': 'salmon',
              'width': 3,
              'dash': 'dashdot',
          }, name=f'{leg1} median'
      ),
                        go.Scatter(y=[0,0.45],x=[amed,amed], line={
              'color': 'salmon',
              'width': 3,
              'dash': 'dot',
          }, name=f'{leg2} median')])

  fig.update_layout(
      autosize=False,
      width=1000,
      height=700,
      title=title,
      title_x =0.5,
      title_y = 0.95,
      font=dict(
          family="sans-serif",
          size=16,
          # color="black"
      ),
      xaxis=dict(
          title=y_title,
          titlefont_size=16,
          tickfont_size=14,
      ),
      yaxis=dict(
          title='Proportion of Responses',
          titlefont_size=16,
          tickfont_size=14,
      ),
      legend=dict(
          x=0.8,
          y=1.0,
          font=dict(
              family="sans-serif",
              size=14,
              # color="black"
          ),
          bgcolor='rgba(255, 255, 255, 0)',
          bordercolor='rgba(255, 255, 255, 0)',
          traceorder='reversed'
      ),
        
      barmode='group',
      bargap=0.15, # gap between bars of adjacent location coordinates.
      bargroupgap=0.1, # gap between bars of the same location coordinate.
      paper_bgcolor = 'rgba(0,0,0,0)',
		  plot_bgcolor = 'rgba(0,0,0,0)'
  )
  return fig
  # fig.write_image('bartest.png', scale=3)
  # files.download('bartest.png')

"""## Descriptive stats"""

print('Shape of undergrad dataset: ', ug.shape)
ug.head()

"""## Plotting the data"""

# plot pie charts to show percentages of responses
pie_texts = {'cols': ['is_online_short', 'country', 'primary_mode', 'preferred_mode', 'preference'], \
             'titles': ['Online learning', 'Countries', 'Primary Mode of Learning', 'Preferred Mode of Learning', 'Preferred Type of Learning'],\
             'colors': [['#440154', '#35b779', '#fde725'], ['#440154','#3e4989','#26828e','#35b779','#b5de2b'], ['#440154','#31688e','#35b779','#fde725'], ['#440154','#31688e','#35b779','#fde725'], ['#440154', '#35b779']],\
             'legend_x': [0.75, 0.75, 0.75, 0.75, 0.65], 'title_y': [0.05, 0.9, 0.9, 0.9, 0.9]}


for i in range(len(pie_texts['cols'])):
  fig = pie_plots(ug, pie_texts['cols'][i], pie_texts['titles'][i], pie_texts['colors'][i], 10, pie_texts['legend_x'][i], pie_texts['title_y'][i])
  fig.show()
  # fig.write_image(f'pie_all_{i}.png', width = 1500, scale=3)
  # files.download(f'pie_all_{i}.png')

# Plot bar charts to show likert scores proportions

scores_title = [f'Level of {i} for Remote Learning' for i in ['Enjoyment', 'Motivation', 'Satisfaction', 'Engagement', 'Distraction', 'Active Partipation']]
scores_title.extend(['Number of Methods Used in Classes', 'Number of Techniques Used outside of Classes'])

y_title = [f'Level of {i}' for i in ['Enjoyment', 'Motivation', 'Satisfaction', 'Engagement', 'Distraction', 'Active Partipation']]
y_title.extend(['Number of Methods Used in Classes', 'Number of Techniques Used outside of Classes'])

bar_texts = {'cols': ['remote_enjoy','remote_motivated', 'remote_satisfied', 'remote_engaging','remote_distracted',\
                      'remote_questions','num_methods', 'num_techniques'], \
             'title': scores_title,\
             'y_title': y_title, 'legend': [['Synchronous', 'Asynchronous'], ['Prefer Remote', 'Prefer In-person']]}

for i in range(len(bar_texts['cols'])):
  fig = bar_plot(ug[ug['primary_mode']=='live'], ug[ug['primary_mode']!='live'], bar_texts['cols'][i],\
           bar_texts['title'][i], bar_texts['y_title'][i], bar_texts['legend'][0][0], bar_texts['legend'][0][1])
  fig.show()
  # fig.write_image(f'bar_sync_async_{i}.png', scale=3)
  # files.download(f'bar_sync_async_{i}.png')

for i in range(len(bar_texts['cols'])):
  fig = bar_plot(ug[ug['preference']=='Online Courses'], ug[ug['preference']=='In-person Courses'], bar_texts['cols'][i],\
           bar_texts['title'][i], bar_texts['y_title'][i], bar_texts['legend'][1][0], bar_texts['legend'][1][1])
  fig.show()
  # fig.write_image(f'bar_prefer_remote_inperson_{i}.png', scale=3)
  # files.download(f'bar_prefer_remote_inperson_{i}.png')

for i in range(len(bar_texts['cols'])):
  fig = bar_plot(ug[ug['primary_mode']=='live'], ug[ug['primary_mode']!='live'], bar_texts['cols'][i],\
           bar_texts['title'][i], bar_texts['y_title'][i], bar_texts['legend'][0][0], bar_texts['legend'][0][1])
  fig.show()

moodle = ug[ug['platforms_used'].str.contains("moodle", case=False) == True]
moodle.name = "moodle"
no_moodle = ug[ug['platforms_used'].str.contains("moodle", case=False) == False]
no_moodle.name = "no_moodle"
subset_ls.append(moodle)
subset_ls.append(no_moodle)
subset_name.append(moodle.name)
subset_name.append(no_moodle.name)
mwu_comparison(moodle, no_moodle)

zoom = ug[ug['platforms_used'].str.contains("zoom", case=False) == True]
zoom.name = "zoom"
no_zoom = ug[ug['platforms_used'].str.contains("zoom", case=False) == False]
no_zoom.name = "no_zoom"
subset_ls.append(zoom)
subset_ls.append(no_zoom)
subset_name.append(zoom.name)
subset_name.append(no_zoom.name)
mwu_comparison(zoom, no_zoom)

collab = ug[ug['platforms_used'].str.contains("collab", case=False) == True]
collab.name = "collab"
no_collab = ug[ug['platforms_used'].str.contains("collab", case=False) == False]
no_collab.name = "no_collab"
subset_ls.append(collab)
subset_ls.append(no_collab)
subset_name.append(collab.name)
subset_name.append(no_collab.name)
mwu_comparison(collab, no_collab)

previous = ug[ug['platforms_used'].str.contains("previous", case=False) == True]
previous.name = "previous"
no_previous = ug[ug['platforms_used'].str.contains("previous", case=False) == False]
no_previous.name = "no_previous"
subset_ls.append(previous)
subset_ls.append(no_previous)
subset_name.append(previous.name)
subset_name.append(no_previous.name)
mwu_comparison(previous, no_previous)

def mwu_one_col(x, col, plat):
  for i in range(len(plat)-1):
    for j in range(i+1, len(plat)):
      a = x[col][(x['platforms_used'].str.contains(plat[i], case=False)) & (x['platforms_used'].str.contains(plat[j], case=False))]
      b = x[col][((x['platforms_used'].str.contains(plat[i], case=False)) & (x['platforms_used'].str.contains(plat[j], case=False))) == False]
      a.name = f'{col}, {plat[i]} and {plat[j]}'
      b.name = f'{col}, not ({plat[i]} and {plat[j]})'
      amed = "{:.3}".format(a.median())
      bmed = "{:.3}".format(b.median())
      d = "{:.3}".format(cohens_d(a,b))
      mwu = stats.mannwhitneyu(a,b, alternative='greater')
      U_a = mwu[0]
      p = "{:.3}".format(mwu[1])
      f = "{:.3}".format(eff(U_a, len(a), len(b)))
      # eta2 = "{:.3}".format(mwu[1] / (a.shape[0] + b.shape[0] - 1))

      print(f'{a.name} size: {len(a)}, {b.name} size: {len(b)}')
      print('MWU results: ', mwu)
      
      print(f'{a.name} median: {amed}')
      print(f'{b.name} median: {bmed}')
      print(f'cohens d: {d}')
      print(f'f: {f}')
      print(f'p: {p}')
      print('-----')

plats = [['Collaborate', 'Email', 'Moodle', 'Previous'], ['Collaborate', 'Moodle', 'Previous'], ['Zoom', 'Moodle', 'Previous'], ['Zoom', 'Collaborate', 'Email', 'Moodle'],\
         ['Zoom', 'Teams', 'Google', 'Collaborate', 'Moodle', 'Discord']]

cols = ["remote_enjoy","remote_motivated", "remote_satisfied","remote_engaging", "remote_questions"]

for i in range(5):
  print('----------')
  mwu_one_col(ug, cols[i], plats[i])

"""# UK vs. others"""

ug['country'].unique()

uk = ug[ug['country'] == 'United Kingdom']
non_uk = ug[ug['country'] != 'United Kingdom']
uk.name = 'uk'
non_uk.name = 'other countries'
subset_ls.append(uk)
subset_ls.append(non_uk)
subset_name.append(uk.name)
subset_name.append(non_uk.name)

mwu_comparison(non_uk, uk)

